# -*- coding: utf-8 -*-
"""NNFL_ANN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i0fpNU6j36jEpy1E2mq3jXzaItss6LzA
"""

import numpy as np
import librosa
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC

import tensorflow as tf

import pandas as pd
data =pd.read_csv("/content/features  - Sheet1 (2).csv")

data.head()

datasets=data.values

import numpy as np

datasets

data.shape

input = datasets[:,1:9]

input.shape

input

output=datasets[:,10]

output.shape

max(input[:,5])

for i in range (0,7):
  input[i] = np.asarray(input[i]).astype(np.float32)
  input[:,i] = input[:,i]/max(input[:,i])

len((np.unique(output)))

from sklearn.preprocessing import OneHotEncoder
import numpy as np

one_hot = np.array(['0', '1', '2', '3','4', '5',
                    '6', '7', '8', '9', '10',
                    '11', '12', '13', '14', '15',
                    '16', '17', '18', '19', '20',
                    '21', '22', '23', '24', '25',
                    '26', '27', '28', '29', '30'])

encoder = OneHotEncoder()

encoded_classes = encoder.fit_transform(one_hot.reshape(-1, 1))

encoded_classes = encoded_classes.toarray()

print(encoded_classes)

one_hot = []
for i in range(len(output)):
  for j in range(len(np.unique(output))):
    if j==0:
      one_hot.append([1,0,0,0,0,0,0,0,0,0])
    elif j==1:
      one_hot.append([0,1,0,0,0,0,0,0,0,0])
    elif j==2:
      one_hot.append([0,0,1,0,0,0,0,0,0,0])
    elif j==3:
      one_hot.append([0,0,0,1,0,0,0,0,0,0])
    elif j==4:
      one_hot.append([0,0,0,0,1,0,0,0,0,0])
    elif j==5:
      one_hot.append([0,0,0,0,0,1,0,0,0,0])
    elif j==6:
      one_hot.append([0,0,0,0,0,0,1,0,0,0])
    elif j==6:
      one_hot.append([0,0,0,0,0,0,0,1,0,0])
    elif j==7:
      one_hot.append([0,0,0,0,0,0,0,0,1,0])
    elif j==8:
      one_hot.append([0,0,0,0,0,0,0,0,0,1])

from keras.utils import np_utils

encoded_output = np_utils.to_categorical(output)

from tensorflow import keras

from keras.models import Sequential

ann_model=Sequential()
ann_model.add(keras.layers.Input(shape=(8,)))
ann_model.add(keras.layers.Dense(9,activation='relu'))
ann_model.add(keras.layers.Dense(16,activation='relu'))
ann_model.add(keras.layers.Dense(32,activation='relu'))
ann_model.add(keras.layers.Dense(16,activation='relu'))
ann_model.add(keras.layers.Dense(9,activation='softmax'))

ann_model.summary()

from tensorflow.keras import optimizers
rms =keras.optimizers.RMSprop(learning_rate=0.001)

ann_model.compile(loss='categorical_crossentropy', optimizer = rms, metrics=['accuracy'])

X_train, X_test, y_train, y_test = train_test_split(input, encoded_output, test_size=0.2, random_state=42)

x_train = np.asarray(X_train).astype(np.float32)
y_train = np.asarray(y_train).astype(np.float32)

tf.convert_to_tensor(X_train, dtype=tf.float32)

from keras import backend as K
X_train1 = K.cast_to_floatx(X_train)
y_train1 = K.cast_to_floatx(y_train)

X_test1 = K.cast_to_floatx(X_test)
y_test1 = K.cast_to_floatx(y_test)

ann_model.fit(X_train1, y_train1, epochs=500, batch_size=2)

ann_model.evaluate(X_test1, y_test1)

